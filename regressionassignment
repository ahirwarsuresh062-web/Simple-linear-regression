{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahirwarsuresh062-web/Simple-linear-regression/blob/main/Welcome_To_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "üîπ SIMPLE LINEAR REGRESSION\n",
        "\n",
        "Q1. What is Simple Linear Regression?\n",
        "\n",
        "Ans. Simple Linear Regression is a method used to find the relationship    between one independent variable (X) and one dependent variable (Y) using a straight line.\n",
        "\n",
        " Example:\n",
        "Predicting marks (Y) based on study hours (X).\n",
        "\n",
        "Q2. Key assumptions of Simple Linear Regression\n",
        "Relationship between X and Y is linear\n",
        "\n",
        "Ans.\n",
        "Errors are independent\n",
        "\n",
        "Errors have constant variance (no heteroscedasticity)\n",
        "\n",
        "Errors are normally distributed\n",
        "\n",
        "No extreme outliers\n",
        "\n",
        "Q3. What does coefficient m represent in Y = mX + c?\n",
        "\n",
        "Ans. m = slope\n",
        "\n",
        "It shows how much Y changes when X increases by 1 unit\n",
        "\n",
        " If m = 2 ‚Üí when X increases by 1, Y increases by 2\n",
        "\n",
        "Q4. What does intercept c represent?\n",
        "\n",
        "Ans. c = value of Y when X = 0\n",
        "\n",
        "It is the starting point of the line\n",
        "\n",
        " Q5. How do we calculate slope ?\n",
        "m\n",
        "=\n",
        "‚àë\n",
        "(\n",
        "X\n",
        "‚àí\n",
        "X\n",
        "Àâ\n",
        ")\n",
        "(\n",
        "Y\n",
        "‚àí\n",
        "Y\n",
        "Àâ\n",
        ")\n",
        "‚àë\n",
        "(\n",
        "X\n",
        "‚àí\n",
        "X\n",
        "Àâ\n",
        ")\n",
        "2\n",
        "m=\n",
        "‚àë(X‚àí\n",
        "X\n",
        "Àâ\n",
        " )\n",
        "2\n",
        "\n",
        "‚àë(X‚àí\n",
        "X\n",
        "Àâ\n",
        " )(Y‚àí\n",
        "Y\n",
        "Àâ\n",
        " )\n",
        "‚Äã\n",
        "\n",
        " In simple words:\n",
        "Slope shows the direction and strength of the relationship.\n",
        "\n",
        "Q6. Purpose of Least Squares Method\n",
        "\n",
        "Ans. It finds the best fitting line\n",
        "\n",
        "It minimizes the sum of squared errors (difference between actual and predicted values)\n",
        "\n",
        "Q7. Interpretation of R¬≤ (Coefficient of Determination)\n",
        "\n",
        "Ans. R¬≤ shows how much variation in Y is explained by X\n",
        "\n",
        "Value lies between 0 and 1\n",
        "\n",
        " R¬≤ = 0.80 ‚Üí 80% variation explained\n",
        "\n",
        "üîπ MULTIPLE LINEAR REGRESSION\n",
        "\n",
        "Q8. What is Multiple Linear Regression?\n",
        "\n",
        "Ans. It studies the relationship between one dependent variable and two or more independent variables.\n",
        "\n",
        " Example:\n",
        "Salary = experience + education + skills\n",
        "\n",
        "Q9. Difference between Simple & Multiple Linear Regression\n",
        "\n",
        "Ans.\n",
        "Simple\tMultiple\n",
        "One X variable\tTwo or more X variables\n",
        "Y = mX + c\tY = b‚ÇÅX‚ÇÅ + b‚ÇÇX‚ÇÇ + c\n",
        "\n",
        "Q10. Key assumptions of Multiple Linear Regression\n",
        "\n",
        "Ans.\n",
        "\n",
        "Linear relationship\n",
        "\n",
        "No multicollinearity\n",
        "\n",
        "Homoscedasticity\n",
        "\n",
        "Errors are independent\n",
        "\n",
        "Normal distribution of errors\n",
        "\n",
        "Q11. What is heteroscedasticity?\n",
        "\n",
        "Ans. When variance of errors is not constant\n",
        "\n",
        "It leads to unreliable results\n",
        "\n",
        " Causes wrong standard errors and tests\n",
        "\n",
        "Q12. How to improve model with high multicollinearity?\n",
        "\n",
        "Ans. Remove highly correlated variables\n",
        "\n",
        "Use Ridge or Lasso regression\n",
        "\n",
        "Use PCA\n",
        "\n",
        "Combine variables\n",
        "\n",
        "Q13. Techniques to transform categorical variables\n",
        "\n",
        "Ans. One-hot encoding\n",
        "\n",
        "Label encoding\n",
        "\n",
        "Dummy variables\n",
        "\n",
        "Q14. Role of interaction terms\n",
        "\n",
        "Ans.Shows how two variables together affect Y\n",
        "\n",
        "Example: education √ó experience\n",
        "\n",
        "Q15. Intercept interpretation: Simple vs Multiple\n",
        "\n",
        "Ans.\n",
        "Simple: Y when X = 0\n",
        "\n",
        "Multiple: Y when all X variables = 0\n",
        "\n",
        "Q16. Significance of slope in regression\n",
        "\n",
        "Ans. Shows direction (+/‚Äì) and strength\n",
        "\n",
        "Affects prediction accuracy\n",
        "\n",
        "Q17. How does intercept give context?\n",
        "\n",
        "Ans. It gives a baseline value\n",
        "\n",
        "Helps understand where prediction starts\n",
        "\n",
        "Q18. Limitations of using R¬≤ alone\n",
        "\n",
        "Ans.\n",
        "Cannot detect overfitting\n",
        "\n",
        "Always increases with more variables\n",
        "\n",
        "Doesn‚Äôt show causation\n",
        "\n",
        "Q19. Interpretation of large standard error\n",
        "\n",
        "Ans.\n",
        "Coefficient estimate is not reliable\n",
        "\n",
        "Variable may be insignificant\n",
        "\n",
        "Q20. Identifying heteroscedasticity in residual plots\n",
        "\n",
        "Ans.\n",
        "Pattern looks like cone or fan shape\n",
        "\n",
        "Important because it affects model validity\n",
        "\n",
        "Q21. High R¬≤ but low adjusted R¬≤ means\n",
        "\n",
        "Ans.\n",
        "Too many irrelevant variables\n",
        "\n",
        "Model is overfitted\n",
        "\n",
        "Q22. Why scale variables?\n",
        "\n",
        "Ans.\n",
        "Needed when variables have different units\n",
        "\n",
        "Improves model performance\n",
        "\n",
        "Important for regularization\n",
        "\n",
        "üîπ POLYNOMIAL REGRESSION\n",
        "\n",
        "Q23. What is polynomial regression?\n",
        "\n",
        "Ans.\n",
        "It models non-linear relationships using polynomial terms.\n",
        "\n",
        "Q24. Difference between linear & polynomial regression\n",
        "\n",
        "Ans.\n",
        "Linear\tPolynomial\n",
        "Straight line\tCurved line\n",
        "Degree = 1\tDegree ‚â• 2\n",
        "\n",
        "Q25. When is polynomial regression used?\n",
        "\n",
        "Ans.\n",
        "When data shows a curved pattern\n",
        "\n",
        "Linear model fails\n",
        "\n",
        "Q26. General equation\n",
        "\n",
        "Ans.\n",
        "\n",
        "Y\n",
        "=\n",
        "a\n",
        "X\n",
        "n\n",
        "+\n",
        "b\n",
        "X\n",
        "n\n",
        "‚àí\n",
        "1\n",
        "+\n",
        "‚ãØ\n",
        "+\n",
        "c\n",
        "Y=aX\n",
        "n\n",
        " +bX\n",
        "n‚àí1\n",
        " +‚ãØ+c\n",
        "\n",
        "Q27. Can polynomial regression be applied to multiple variables?\n",
        "\n",
        "Ans.\n",
        " Yes\n",
        "It can include multiple variables with polynomial terms\n",
        "\n",
        "Q28. Limitations of polynomial regression\n",
        "\n",
        "Ans.\n",
        "Overfitting\n",
        "\n",
        "Poor extrapolation\n",
        "\n",
        "Sensitive to outliers\n",
        "\n",
        "Q29. Methods to choose polynomial degree\n",
        "Ans.\n",
        "Cross-validation\n",
        "\n",
        "Adjusted R¬≤\n",
        "\n",
        "AIC / BIC\n",
        "\n",
        "Error metrics (MSE, RMSE)\n",
        "\n",
        "Q30. Importance of visualization\n",
        "\n",
        "Ans.\n",
        "Helps identify non-linear patterns\n",
        "\n",
        "Helps choose correct degree\n",
        "\n",
        "Avoids overfitting\n",
        "\n",
        "Q31. Polynomial regression in Python\n",
        "\n",
        "Ans.\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_poly, y)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ieZp0OlOqlh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5N2_yppAyRif"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "esIp4ySIyJex"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
